{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087963bb-7480-4cae-bc11-d18c06e0f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import geometry\n",
    "from shapely.ops import cascaded_union\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062d3ce6-e3b6-44df-9bb4-6f4fab944cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\Data\\\\20231205-4T1F170-1128-6_T7\\\\contour_0.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_folder = r'E:\\Data\\20231205-4T1F170-1128-6_T7'\n",
    "contour_filename_list = [_f for _f in glob.glob(data_folder+os.sep+'*') if 'contour_' in _f and 'position' not in _f]\n",
    "print(contour_filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8696d51c-d66c-4e35-8c45-f0e0b992a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get position file for 1 contours.\n",
      "save 426 coordinates into file: E:\\Data\\20231205-4T1F170-1128-6_T7\\contour_0_positions.txt\n",
      "Save 426 coordinates into the merged file: E:\\Data\\20231205-4T1F170-1128-6_T7\\positions_all.txt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get position file for {len(contour_filename_list)} contours.\")\n",
    "# merged positions for all positions\n",
    "postions_all = []\n",
    "\n",
    "for contour_filename in contour_filename_list:\n",
    "    # read contour coords\n",
    "    points = pd.read_csv(contour_filename, header=None, sep=',')\n",
    "    points.columns=['X', 'Y']\n",
    "    # convert to polygon\n",
    "    \n",
    "    grid_size = 200 # um\n",
    "\n",
    "    tissue = geometry.Polygon(points.values)\n",
    "    grid_center = np.round(np.array(tissue.centroid.coords)[0], 1)\n",
    "    grid_inds = [np.arange(np.floor( (np.min(points['X'])-grid_center[0])/grid_size ), \n",
    "                  np.ceil( (max(points['X'])-grid_center[0])/grid_size )+1 ),\n",
    "         np.arange(np.floor( (np.min(points['Y'])-grid_center[1])/grid_size ), \n",
    "                  np.ceil( (max(points['Y'])-grid_center[1])/grid_size )+1 ),\n",
    "        ]\n",
    "            \n",
    "    grids = np.array(np.meshgrid(*grid_inds))#.reshape(len(grid_inds),-1).transpose()\n",
    "    # generate tiles in snake style\n",
    "\n",
    "    sorted_grids = []\n",
    "    for _iy in np.arange(grids.shape[-1]):\n",
    "        _line_grids = grids[:,:,_iy]\n",
    "        if _iy % 2 == 0:\n",
    "            sorted_grids.append(_line_grids)\n",
    "        else:\n",
    "            sorted_grids.append(np.fliplr(_line_grids))\n",
    "    \n",
    "    grids = np.concatenate(sorted_grids, axis=1).transpose()\n",
    "    \n",
    "    # get to positions coord inside the grid      \n",
    "    positions = []\n",
    "\n",
    "    for _i, _grid in enumerate(grids):\n",
    "        _grid_position = _grid * grid_size + grid_center\n",
    "        #print(_grid_position)\n",
    "        # get each grid point\n",
    "        _grid_point = geometry.Point(_grid_position)\n",
    "        _fov_shape = geometry.Polygon([\n",
    "                _grid_position + [-grid_size/2, -grid_size/2], \n",
    "                _grid_position + [grid_size/2, -grid_size/2], \n",
    "                _grid_position + [grid_size/2, grid_size/2], \n",
    "                _grid_position + [-grid_size/2, grid_size/2], \n",
    "            ])\n",
    "        # calculate intersect\n",
    "        _intersect = _fov_shape.intersection(tissue)\n",
    "        if _intersect.area > 0:\n",
    "            positions.append(_grid_position)\n",
    "            postions_all.append(_grid_position)\n",
    "    positions = np.array(positions)\n",
    "    #print(np.shape(positions))\n",
    "    \n",
    "    \n",
    "    overwrite = False\n",
    "    save_filename = contour_filename.replace('.txt', '_positions.txt')\n",
    "\n",
    "    if os.path.exists(save_filename) and not overwrite:\n",
    "        print(f\"file: {save_filename} already exist, skip!\")\n",
    "    else:\n",
    "        print(f\"save {len(positions)} coordinates into file: {save_filename}\")\n",
    "        np.savetxt(save_filename, np.round(positions,2), delimiter=',', fmt='%.2f')\n",
    "\n",
    "    \n",
    "    \n",
    "postions_all =np.array(postions_all)\n",
    "merged_save_filename = os.path.join(data_folder, r'positions_all.txt')\n",
    "exp_date = data_folder.split('\\\\')[-1].split('-')[0]\n",
    "analysis_save_filename = os.path.join(data_folder, f'{exp_date}_positions_all.txt')\n",
    "\n",
    "if os.path.exists(merged_save_filename) and not overwrite:\n",
    "    print(f\"file: {merged_save_filename} already exist, skip!\")\n",
    "else:\n",
    "    print(f\"Save {len(postions_all)} coordinates into the merged file: {merged_save_filename}\")\n",
    "    np.savetxt(merged_save_filename, np.round(postions_all,2), delimiter=',', fmt='%.2f')\n",
    "    #np.savetxt(analysis_save_filename, np.round(postions_all,2), delimiter=',', fmt='%.2f')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc28d1-08b2-424c-9bd0-2c462f7af5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a1d4a-0e7b-4542-9f48-c0d5882ebacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postanalysis",
   "language": "python",
   "name": "postanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
